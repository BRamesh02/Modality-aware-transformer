{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa8638e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93655533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on: mps\n"
     ]
    }
   ],
   "source": [
    "current_dir = Path.cwd()\n",
    "project_root = current_dir.parent\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.append(str(project_root))\n",
    "\n",
    "from src.utils.data_loader import load_and_merge_data\n",
    "from src.models.dataset import FinancialDataset, get_annual_splits, prepare_scaled_fold\n",
    "\n",
    "DATA_DIR = project_root / \"data\"\n",
    "BATCH_SIZE = 64\n",
    "WINDOW_SIZE = 60\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device(\"cuda\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    DEVICE = torch.device(\"mps\")\n",
    "else:\n",
    "    DEVICE = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"Running on: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f5370d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data from: /Users/audricsicard/Documents/VSCode/AML Project/Modality-aware-transformer/data\n",
      "Loading datasets...\n",
      "\n",
      "--- Merging Data ---\n",
      "Merged Market: (3254401, 12)\n",
      "Merged Ratios: (3254401, 17)\n",
      "Merged Macro: (3254401, 24)\n",
      "Merged Text: (3254401, 31)\n",
      "Filling NaN values...\n",
      "Keeping records between 2010-01-01 and 2023-12-15...\n",
      "Done! Final Data Shape: (2500247, 31)\n",
      "\n",
      "Generated 8 Walk-Forward splits.\n"
     ]
    }
   ],
   "source": [
    "# Load the Point-in-Time merged dataframe\n",
    "# This handles the merging of Price, Ratios, Macro, and Text + NaNs filling\n",
    "df_main = load_and_merge_data(DATA_DIR)\n",
    "\n",
    "# Generate the Walk-Forward Anchors (e.g., 2010-2015 Train, 2016 Val, 2017 Test)\n",
    "splits = get_annual_splits(\n",
    "    df_main, start_year=2010, train_years=5, val_years=1, test_years=1\n",
    ")\n",
    "\n",
    "print(f\"\\nGenerated {len(splits)} Walk-Forward splits.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d602b8af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Debug Universe (5 Stocks): [90373. 89508. 81677. 10890. 23712.]\n",
      "Verifying Coverage for Validation Period: 2015-01-01 to 2015-12-31\n",
      "Numerical Features (22): ['mkt_log_ret', 'mkt_cap_rank', 'mkt_mom_1m', 'mkt_mom_3m', 'mkt_volatility', 'mkt_drawdown', 'mkt_turnover', 'mkt_rel_vol', 'mkt_liq_risk', 'ratio_pb', 'ratio_ey', 'ratio_roe', 'ratio_de', 'ratio_div_yield', 'macro_unemp_rate', 'macro_unemp_delta', 'macro_cpi_yoy', 'macro_ppi_yoy', 'macro_yield_curve', 'macro_risk_free', 'macro_vix', 'has_news']\n",
      "Text Features bar Embedding Vector (5): ['sent_score_mean', 'sent_pos_mean', 'sent_neg_mean', 'sent_score_std', 'log_n_news']\n",
      "Converting to PyTorch Tensors...\n",
      "Dataset Ready. Samples: 1260 (Filtered by 2015-01-01 to 2015-12-31)\n",
      "\n",
      "--- Theoretical Valid Samples ---\n",
      "Expected Samples (Manual Logic): 1260\n",
      "Actual Samples (Dataset Len):    1260\n",
      "Loader Yielded:                  1260\n",
      "\n",
      "✅ SUCCESS: All valid test rows have a prediction.\n"
     ]
    }
   ],
   "source": [
    "# --- 2. SELECT DEBUG UNIVERSE ---\n",
    "# Pick 5 random stocks to simulate a \"Mini Universe\"\n",
    "all_permnos = df_main[\"permno\"].unique()\n",
    "debug_permnos = np.random.choice(all_permnos, size=5, replace=False)\n",
    "print(f\"Debug Universe (5 Stocks): {debug_permnos}\")\n",
    "\n",
    "# Filter Main Data to just these stocks\n",
    "mask_debug = df_main[\"permno\"].isin(debug_permnos)\n",
    "df_debug = df_main[mask_debug].copy()\n",
    "\n",
    "num_cols = [\n",
    "    \"mkt_log_ret\",\n",
    "    \"mkt_cap_rank\",\n",
    "    \"mkt_mom_1m\",\n",
    "    \"mkt_mom_3m\",\n",
    "    \"mkt_volatility\",\n",
    "    \"mkt_drawdown\",\n",
    "    \"mkt_turnover\",\n",
    "    \"mkt_rel_vol\",\n",
    "    \"mkt_liq_risk\",\n",
    "    \"ratio_pb\",\n",
    "    \"ratio_ey\",\n",
    "    \"ratio_roe\",\n",
    "    \"ratio_de\",\n",
    "    \"ratio_div_yield\",\n",
    "    \"macro_unemp_rate\",\n",
    "    \"macro_unemp_delta\",\n",
    "    \"macro_cpi_yoy\",\n",
    "    \"macro_ppi_yoy\",\n",
    "    \"macro_yield_curve\",\n",
    "    \"macro_risk_free\",\n",
    "    \"macro_vix\",\n",
    "]\n",
    "\n",
    "\n",
    "# --- 1. SETUP: Pick a specific split ---\n",
    "# We will test the 'Validation' period of the first split\n",
    "split = splits[0]\n",
    "val_start_str, val_end_str = split[\"val\"]\n",
    "print(f\"Verifying Coverage for Validation Period: {val_start_str} to {val_end_str}\")\n",
    "\n",
    "# --- 2. PREPARE DATA (Standard Workflow) ---\n",
    "# Use your helper to get the Warm Validation DataFrame\n",
    "_, df_val_warm, _ = prepare_scaled_fold(df_debug, num_cols, split, buffer_days=90)\n",
    "\n",
    "# Initialize Dataset with STRICT limits\n",
    "val_dataset = FinancialDataset(\n",
    "    df_val_warm, window_size=60, min_date=val_start_str, max_date=val_end_str\n",
    ")\n",
    "\n",
    "# IMPORTANT: Use batch_size=1 and drop_last=FALSE to count every single item\n",
    "val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False, drop_last=False)\n",
    "\n",
    "# --- 3. CALCULATE EXPECTED COUNT ---\n",
    "# We need to know how many rows in the raw 'df_val_warm'\n",
    "# are actually valid targets (date >= val_start AND have 60 days of history).\n",
    "\n",
    "# A. Filter to official range\n",
    "dates = pd.to_datetime(df_val_warm[\"date\"])\n",
    "val_start_ts = pd.Timestamp(val_start_str)\n",
    "val_end_ts = pd.Timestamp(val_end_str)\n",
    "\n",
    "# B. Strict filtering logic (replicating Dataset logic manually)\n",
    "expected_count = 0\n",
    "permnos = df_val_warm[\"permno\"].values\n",
    "# Find start indices of every stock in the warm df\n",
    "change_points = np.where(permnos[:-1] != permnos[1:])[0] + 1\n",
    "start_points = np.concatenate(([0], change_points))\n",
    "end_points = np.concatenate((change_points, [len(permnos)]))\n",
    "\n",
    "print(\"\\n--- Theoretical Valid Samples ---\")\n",
    "for start, end in zip(start_points, end_points):\n",
    "    stock_len = end - start\n",
    "    if stock_len > 60:\n",
    "        # The window ends at index 'k'.\n",
    "        # For a window ending at 'k', the input is [k-60 : k].\n",
    "        # The target is at 'k-1' (The last day of input window? No, target is usually aligned to last day).\n",
    "        # Let's align with your Dataset logic:\n",
    "        # Window: [i : i+60]\n",
    "        # Target Index: i + 60 - 1\n",
    "\n",
    "        # We iterate through all possible starts 'i'\n",
    "        for i in range(start, end - 60 + 1):\n",
    "            target_idx = i + 60 - 1\n",
    "            target_date = dates.iloc[target_idx]\n",
    "\n",
    "            # Count if target is within validation range\n",
    "            if val_start_ts <= target_date <= val_end_ts:\n",
    "                expected_count += 1\n",
    "\n",
    "print(f\"Expected Samples (Manual Logic): {expected_count}\")\n",
    "print(f\"Actual Samples (Dataset Len):    {len(val_dataset)}\")\n",
    "\n",
    "# --- 4. RUN LOADER TO VERIFY ---\n",
    "actual_count = 0\n",
    "for batch in val_loader:\n",
    "    actual_count += batch[\"y\"].shape[0]\n",
    "\n",
    "print(f\"Loader Yielded:                  {actual_count}\")\n",
    "\n",
    "# --- 5. VERDICT ---\n",
    "if expected_count == actual_count == len(val_dataset):\n",
    "    print(\"\\n✅ SUCCESS: All valid test rows have a prediction.\")\n",
    "else:\n",
    "    print(\"\\n❌ FAILURE: Mismatch detected.\")\n",
    "    diff = expected_count - actual_count\n",
    "    print(f\"Missing Samples: {diff}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7de198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Batch Shapes ---\n",
      "Num Features:  torch.Size([1, 60, 22])  (Batch, Window, Feats)\n",
      "Text Features: torch.Size([1, 60, 773]) (Batch, Window, Emb+Scalars)\n",
      "Target:        torch.Size([1])      (Batch)\n"
     ]
    }
   ],
   "source": [
    "# Check one batch\n",
    "batch = next(iter(val_loader))\n",
    "\n",
    "x_num = batch[\"x_num\"].to(DEVICE)\n",
    "x_text = batch[\"x_text\"].to(DEVICE)\n",
    "y = batch[\"y\"].to(DEVICE)\n",
    "\n",
    "print(\"--- Batch Shapes ---\")\n",
    "print(f\"Num Features:  {x_num.shape}  (Batch, Window, Feats)\")\n",
    "print(f\"Text Features: {x_text.shape} (Batch, Window, Emb+Scalars)\")\n",
    "print(f\"Target:        {y.shape}      (Batch)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a147c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 5000):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(\n",
    "            torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model)\n",
    "        )\n",
    "        pe = torch.zeros(max_len, 1, d_model)\n",
    "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer(\"pe\", pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[: x.size(0)]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8345910f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CanonicalEncoder(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_input_dim: int,\n",
    "        text_input_dim: int,\n",
    "        d_model: int = 128,\n",
    "        nhead: int = 4,\n",
    "        num_layers: int = 2,\n",
    "        dropout: float = 0.2,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        The Baseline: A Standard Transformer with Early Fusion.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        # --- 1. Balanced Projection (Early Fusion) ---\n",
    "        # We project both inputs to d_model/2 so they sum to d_model when concatenated.\n",
    "        # This gives equal bandwidth to both modalities, just like MAT.\n",
    "        half_dim = d_model // 2\n",
    "\n",
    "        self.num_proj = nn.Sequential(\n",
    "            nn.Linear(num_input_dim, half_dim),\n",
    "            nn.BatchNorm1d(60),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "\n",
    "        self.text_proj = nn.Sequential(\n",
    "            nn.Linear(text_input_dim, half_dim),\n",
    "            nn.BatchNorm1d(60),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "\n",
    "        # --- 2. Positional Encoding ---\n",
    "        self.pos_encoder = PositionalEncoding(d_model, dropout)\n",
    "\n",
    "        # --- 3. The Transformer Backbone ---\n",
    "        # Standard PyTorch Transformer implementation.\n",
    "        # It treats the fused vector [Price_Info, Text_Info] as one single concept.\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=d_model,\n",
    "            nhead=nhead,\n",
    "            dim_feedforward=d_model * 4,\n",
    "            dropout=dropout,\n",
    "            activation=\"gelu\",\n",
    "            batch_first=True,\n",
    "            norm_first=True,\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
    "\n",
    "    def forward(self, x_num, x_text):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x_num: [Batch, 60, 20]\n",
    "            x_text: [Batch, 60, 773]\n",
    "        Returns:\n",
    "            memory: [Batch, 60, 128] (Single stream output)\n",
    "        \"\"\"\n",
    "        # 1. Project Modalities independently\n",
    "        x_n = self.num_proj(x_num)  # [Batch, 60, 64]\n",
    "        x_t = self.text_proj(x_text)  # [Batch, 60, 64]\n",
    "\n",
    "        # 2. Early Concatenation (The key difference from MAT)\n",
    "        # We fuse them immediately. The transformer now sees one vector of size 128.\n",
    "        x_combined = torch.cat([x_n, x_t], dim=2)  # [Batch, 60, 128]\n",
    "\n",
    "        # 3. Add Positional Encoding\n",
    "        # (Transpose required for our PE implementation)\n",
    "        x_combined = x_combined.transpose(0, 1)  # [60, Batch, 128]\n",
    "        x_combined = self.pos_encoder(x_combined)\n",
    "        x_combined = x_combined.transpose(0, 1)  # [Batch, 60, 128]\n",
    "\n",
    "        # 4. Process with Standard Transformer\n",
    "        memory = self.transformer(x_combined)\n",
    "\n",
    "        return memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df721835",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    Section 3.2.1: Feature-Level Attention.\n",
    "    Now returns BOTH the weighted input and the importance scores.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_dim):\n",
    "        super().__init__()\n",
    "        self.attn = nn.Sequential(\n",
    "            nn.Linear(input_dim, input_dim),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(input_dim, input_dim),\n",
    "            nn.Softmax(dim=-1),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 1. Compute Importance Scores [Batch, Seq, Input_Dim]\n",
    "        weights = self.attn(x)\n",
    "\n",
    "        # 2. Re-weight the input\n",
    "        x_weighted = x * weights\n",
    "\n",
    "        # 3. Return BOTH (So we can reuse weights later)\n",
    "        return x_weighted, weights\n",
    "\n",
    "\n",
    "class MATEncoderLayer(nn.Module):\n",
    "    \"\"\"\n",
    "    A single layer of the MAT Encoder that handles:\n",
    "    1. Intra-Modal Attention (Self-Attention within stream)\n",
    "    2. Inter-Modal Attention (Cross-Attention between streams)\n",
    "    3. Feed Forward\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, d_model, nhead, dim_feedforward, dropout):\n",
    "        super().__init__()\n",
    "\n",
    "        # --- 1. Intra-Modal (Self Attention) ---\n",
    "        self.self_attn_num = nn.MultiheadAttention(\n",
    "            d_model, nhead, dropout=dropout, batch_first=True\n",
    "        )\n",
    "        self.self_attn_text = nn.MultiheadAttention(\n",
    "            d_model, nhead, dropout=dropout, batch_first=True\n",
    "        )\n",
    "\n",
    "        self.norm1_num = nn.LayerNorm(d_model)\n",
    "        self.norm1_text = nn.LayerNorm(d_model)\n",
    "\n",
    "        # --- 2. Inter-Modal (Cross Attention) ---\n",
    "        # Num queries Text, Text queries Num\n",
    "        self.cross_attn_num = nn.MultiheadAttention(\n",
    "            d_model, nhead, dropout=dropout, batch_first=True\n",
    "        )\n",
    "        self.cross_attn_text = nn.MultiheadAttention(\n",
    "            d_model, nhead, dropout=dropout, batch_first=True\n",
    "        )\n",
    "\n",
    "        self.norm2_num = nn.LayerNorm(d_model)\n",
    "        self.norm2_text = nn.LayerNorm(d_model)\n",
    "\n",
    "        # --- 3. Feed Forward ---\n",
    "        self.ff_num = nn.Sequential(\n",
    "            nn.Linear(d_model, dim_feedforward),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(dim_feedforward, d_model),\n",
    "        )\n",
    "        self.ff_text = nn.Sequential(\n",
    "            nn.Linear(d_model, dim_feedforward),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(dim_feedforward, d_model),\n",
    "        )\n",
    "\n",
    "        self.norm3_num = nn.LayerNorm(d_model)\n",
    "        self.norm3_text = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x_num, x_text):\n",
    "        # --- Step 1: Self Attention (Intra) ---\n",
    "        # Learn temporal patterns independently\n",
    "        attn_n, _ = self.self_attn_num(x_num, x_num, x_num)\n",
    "        x_num = self.norm1_num(x_num + self.dropout(attn_n))\n",
    "\n",
    "        attn_t, _ = self.self_attn_text(x_text, x_text, x_text)\n",
    "        x_text = self.norm1_text(x_text + self.dropout(attn_t))\n",
    "\n",
    "        # --- Step 2: Cross Attention (Inter) ---\n",
    "        # Exchange information between streams\n",
    "        # Num Stream looks at Text Stream\n",
    "        attn_n_cross, _ = self.cross_attn_num(query=x_num, key=x_text, value=x_text)\n",
    "        x_num_mixed = self.norm2_num(x_num + self.dropout(attn_n_cross))\n",
    "\n",
    "        # Text Stream looks at Num Stream\n",
    "        attn_t_cross, _ = self.cross_attn_text(query=x_text, key=x_num, value=x_num)\n",
    "        x_text_mixed = self.norm2_text(x_text + self.dropout(attn_t_cross))\n",
    "\n",
    "        # --- Step 3: Feed Forward ---\n",
    "        ff_n = self.ff_num(x_num_mixed)\n",
    "        x_num_out = self.norm3_num(x_num_mixed + self.dropout(ff_n))\n",
    "\n",
    "        ff_t = self.ff_text(x_text_mixed)\n",
    "        x_text_out = self.norm3_text(x_text_mixed + self.dropout(ff_t))\n",
    "\n",
    "        return x_num_out, x_text_out\n",
    "\n",
    "\n",
    "class MATEncoder(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_input_dim: int,\n",
    "        text_input_dim: int,\n",
    "        d_model: int = 128,\n",
    "        nhead: int = 4,\n",
    "        num_layers: int = 2,\n",
    "        dropout: float = 0.2,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        # 1. Feature Attention (Returns weights now)\n",
    "        self.num_feat_attn = FeatureAttention(num_input_dim)\n",
    "        self.text_feat_attn = FeatureAttention(text_input_dim)\n",
    "\n",
    "        # 2. Weight Projectors (NEW)\n",
    "        # We need to map the Feature Weights (dim 20 or 773) to d_model (128)\n",
    "        # to apply them to the Encoder Output.\n",
    "        self.num_weight_proj = nn.Sequential(\n",
    "            nn.Linear(num_input_dim, d_model),\n",
    "            nn.Sigmoid(),  # Gating (0-1)\n",
    "        )\n",
    "        self.text_weight_proj = nn.Sequential(\n",
    "            nn.Linear(text_input_dim, d_model), nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        # 3. Standard Projections (Input -> d_model)\n",
    "        self.num_proj = nn.Sequential(\n",
    "            nn.Linear(num_input_dim, d_model),\n",
    "            nn.BatchNorm1d(60),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "\n",
    "        self.text_proj = nn.Sequential(\n",
    "            nn.Linear(text_input_dim, d_model),\n",
    "            nn.BatchNorm1d(60),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "        )\n",
    "\n",
    "        self.pos_encoder = PositionalEncoding(d_model, dropout)\n",
    "\n",
    "        self.layers = nn.ModuleList(\n",
    "            [\n",
    "                MATEncoderLayer(d_model, nhead, d_model * 4, dropout)\n",
    "                for _ in range(num_layers)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    def forward(self, x_num, x_text):\n",
    "        # A. Feature Attention (Capture the Weights)\n",
    "        # w_num: [Batch, 60, 20]\n",
    "        # w_text: [Batch, 60, 773]\n",
    "        x_num, w_num = self.num_feat_attn(x_num)\n",
    "        x_text, w_text = self.text_feat_attn(x_text)\n",
    "\n",
    "        # B. Project Input to d_model\n",
    "        h_num = self.num_proj(x_num)\n",
    "        h_text = self.text_proj(x_text)\n",
    "\n",
    "        # C. Positional Encoding\n",
    "        h_num = self.pos_encoder(h_num.transpose(0, 1)).transpose(0, 1)\n",
    "        h_text = self.pos_encoder(h_text.transpose(0, 1)).transpose(0, 1)\n",
    "\n",
    "        # D. MAT Processing (The Context Learning)\n",
    "        # This mixes information over time and between modalities\n",
    "        for layer in self.layers:\n",
    "            h_num, h_text = layer(h_num, h_text)\n",
    "\n",
    "        # E. RE-WEIGHTING (The Step I Missing)\n",
    "        # We project the original Feature Weights to the hidden size\n",
    "        # and use them to \"Gate\" the final output.\n",
    "        # This ensures the model output respects the original feature importance.\n",
    "\n",
    "        # [Batch, 60, 20] -> [Batch, 60, 128]\n",
    "        gate_num = self.num_weight_proj(w_num)\n",
    "        # [Batch, 60, 773] -> [Batch, 60, 128]\n",
    "        gate_text = self.text_weight_proj(w_text)\n",
    "\n",
    "        # Apply the Gate\n",
    "        h_num_final = h_num * gate_num\n",
    "        h_text_final = h_text * gate_text\n",
    "\n",
    "        return h_num_final, h_text_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d27167c",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################## PAS IMPORTANT ##################################\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "\n",
    "# --- 1. Canonical Baseline (Single Stream) ---\n",
    "class BaselineCanonical(nn.Module):\n",
    "    def __init__(self, encoder, d_model=128):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "\n",
    "        # Simple Regressor\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(d_model, 64), nn.GELU(), nn.Dropout(0.1), nn.Linear(64, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x_num, x_text):\n",
    "        # Encoder returns single memory [Batch, Seq, Dim]\n",
    "        memory = self.encoder(x_num, x_text)\n",
    "\n",
    "        # Pooling: Take the last step (Most recent day)\n",
    "        last_step = memory[:, -1, :]\n",
    "\n",
    "        return self.head(last_step)\n",
    "\n",
    "\n",
    "# --- 2. MAT Baseline (Dual Stream) ---\n",
    "class BaselineMAT(nn.Module):\n",
    "    def __init__(self, encoder, d_model=128):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "\n",
    "        # Fusion Layer: Combine Num (128) + Text (128) -> 128\n",
    "        self.fusion = nn.Sequential(\n",
    "            nn.Linear(d_model * 2, d_model), nn.LayerNorm(d_model), nn.GELU()\n",
    "        )\n",
    "\n",
    "        # Same Regressor Head as Canonical for fair comparison\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(d_model, 64), nn.GELU(), nn.Dropout(0.1), nn.Linear(64, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x_num, x_text):\n",
    "        # Encoder returns TWO memories\n",
    "        mem_num, mem_text = self.encoder(x_num, x_text)\n",
    "\n",
    "        # Pooling: Take last step from BOTH\n",
    "        last_num = mem_num[:, -1, :]  # [Batch, 128]\n",
    "        last_text = mem_text[:, -1, :]  # [Batch, 128]\n",
    "\n",
    "        # Fuse\n",
    "        combined = torch.cat([last_num, last_text], dim=-1)  # [Batch, 256]\n",
    "        fused = self.fusion(combined)  # [Batch, 128]\n",
    "\n",
    "        return self.head(fused)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
